#!/bin/bash

# BullsBears AI Models Setup Script

# Model list with sizes (approximate) â€“ Updated November 10, 2025
declare -A MODELS=(
    # LOCAL â€“ RunPod only (what actually runs on your hardware)
    ["finma-7b"]="4.2GB"        # Prescreen Agent â€“ ACTIVE â†’ exactly 75 SHORT_LIST (one call daily)

    # CLOUD â€“ API only (zero local VRAM, zero infra)
    ["groq-llama3.2-11b-vision"]="0GB"   # Vision Agent â€“ 75 charts â†’ 6 boolean flags
    ["grok-api"]="0GB"                   # Social + News + Events + Polymarket context
    ["deepseek-v3"]="0GB"                # Arbitrator (Mon & Sat)
    ["gemini-2.5-pro"]="0GB"             # Arbitrator (Tue & Sun)
    ["grok-4"]="0GB"                     # Arbitrator (Wed)
    ["claude-sonnet-4"]="0GB"            # Arbitrator (Thu)
    ["gpt-5"]="0GB"                      # Arbitrator (Fri â€“ o3 mode)
)

echo ""
echo "ðŸ“¦ Pulling required models..."
echo "Total estimated size: ~265GB"
echo ""


echo "ðŸŽ¯ Model setup complete!"
echo ""
echo "ðŸ“Š Available models:"
ollama list

echo ""
echo "ðŸš€ BullsBears AI inference server is ready!"
echo "   API endpoint: http://localhost:11434"
echo "   Health check: http://localhost:11434/api/tags"
